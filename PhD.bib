Automatically generated by Mendeley Desktop 1.13.2-dev1
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@book{corrochano2001geometric,
author = {Bayro-Corrochano, Eduardo},
publisher = {Springer},
title = {{Geometric Computing for Perception Action Systems: Concepts, Algorithms, and Scientific Applications}},
year = {2001}
}
@article{Gong2009,
author = {Gong, Liyu and Wang, Tianjiang and Liu, Fang and Chen, Gang},
file = {:home/fradelg/Google Drive/TESIS/bib/spatiogram2009gong.pdf:pdf},
isbn = {9781424442911},
journal = {IEEE International Conference on Multimedia and Expo (ICME)},
pages = {582--585},
publisher = {IEEE},
title = {{A Lie Group Based Spatiogram Similarity Measure}},
year = {2009}
}
@article{davison2007monoslam,
author = {Davison, A J and Reid, I D and Molton, N D and Stasse, O},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
number = {6},
pages = {1052--1067},
publisher = {IEEE},
title = {{MonoSLAM: Real-time single camera SLAM}},
volume = {29},
year = {2007}
}
@article{chambolle2011first,
author = {Chambolle, Antonin and Pock, Thomas},
journal = {Journal of Mathematical Imaging and Vision},
number = {1},
pages = {120--145},
publisher = {Springer},
title = {{A first-order primal-dual algorithm for convex problems with applications to imaging}},
volume = {40},
year = {2011}
}
@article{konolige2008frameslam,
author = {Konolige, Kurt and Agrawal, Motilal},
journal = {IEEE Transactions on Robotics},
number = {5},
pages = {1066--1077},
publisher = {IEEE},
title = {{FrameSLAM: From bundle adjustment to real-time visual mapping}},
volume = {24},
year = {2008}
}
@article{zhang2000flexible,
author = {Zhang, Zhengyou},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {11},
pages = {1330--1334},
publisher = {IEEE},
title = {{A flexible new technique for camera calibration}},
volume = {22},
year = {2000}
}
@inproceedings{seitz2006comparison,
author = {Seitz, S M and Curless, B and Diebel, J and Scharstein, D and Szeliski, R},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (VCPR)},
pages = {519--528},
publisher = {IEEE},
title = {{A comparison and evaluation of multi-view stereo reconstruction algorithms}},
volume = {1},
year = {2006}
}
@article{Steinbr2014,
abstract = {In this paper we propose a novel volumetric multi-resolution mapping system for RGB-D images that runs on a standard CPU in real-time. Our approach generates a textured triangle mesh from a signed distance function that it continuously updates as new RGB-D images arrive. We propose to use an octree as the primary data structure which allows us to represent the scene at multiple scales. Furthermore, it allows us to grow the reconstruction volume dynamically. As most space is either free or unknown, we allocate and update only those voxels that are located in a narrow band around the observed surface. In contrast to a regular grid, this approach saves enormous amounts of memory and computation time. The major challenge is to generate and maintain a consistent triangle mesh, as neighboring cells in the octree are more difficult to find and may have different resolutions. To remedy this, we present in this paper a novel algorithm that keeps track of these dependencies, and efficiently updates corresponding parts of the triangle mesh. In our experiments, we demonstrate the real-time capability on a large set of RGB-D sequences. As our approach does not require a GPU, it is well suited for applications on mobile or flying robots with limited computational resources. I.},
author = {Steinbr, Frank and Cremers, Daniel},
file = {:home/fradelg/Google Drive/TESIS/bib/steinbruecker2014dense.pdf:pdf},
isbn = {9781479936847},
journal = {2014 IEEE International Conference on Robotics and Automation},
pages = {2021--2028},
title = {{Volumetric 3D Mapping in Real-Time on a CPU}},
year = {2014}
}
@article{hartley1997triangulation,
author = {Hartley, Richard I and Sturm, Peter},
file = {:home/fradelg/Google Drive/TESIS/bib/hartley1997triangulation.pdf:pdf},
journal = {Computer Vision and Image Understanding},
number = {2},
pages = {146--157},
publisher = {Elsevier},
title = {{Triangulation}},
volume = {68},
year = {1997}
}
@article{yang2010image,
author = {Yang, J and Wright, J and Huang, T S and Ma, Y},
journal = {Image Processing, IEEE Transactions on},
number = {11},
pages = {2861--2873},
publisher = {IEEE},
title = {{Image super-resolution via sparse representation}},
volume = {19},
year = {2010}
}
@article{kummerle2009measuring,
author = {K\"{u}mmerle, R and Steder, B and Dornhege, C and Ruhnke, M and Grisetti, G and Stachniss, C and Kleiner, A},
journal = {Autonomous Robots},
number = {4},
pages = {387--407},
publisher = {Springer},
title = {{On measuring the accuracy of SLAM algorithms}},
volume = {27},
year = {2009}
}
@article{hernandez2008multiview,
author = {Hernandez, C and Vogiatzis, G and Cipolla, R},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {3},
pages = {548--554},
publisher = {IEEE},
title = {{Multiview photometric stereo}},
volume = {30},
year = {2008}
}
@inproceedings{davison2003real,
author = {Davison, A J},
booktitle = {Proceedings of the 9th IEEE International Conference on Computer Vision},
pages = {1403--1410},
publisher = {IEEE},
title = {{Real-time simultaneous localisation and mapping with a single camera}},
year = {2003}
}
@inproceedings{lim2012realtime,
author = {Lim, Hyon and Sinha, Sudipta N and Cohen, Michael F and Uyttendaele, Matthew},
booktitle = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)},
month = jun,
title = {{Real-time Image-based 6-DOF Localization in Large-Scale Environments}},
year = {2012}
}
@inproceedings{zach2008fast,
author = {Zach, Christopher and Gallup, David and Frahm, J-M},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition Workshops},
organization = {IEEE},
pages = {1--7},
title = {{Fast gain-adaptive KLT tracking on the GPU}},
year = {2008}
}
@article{kim2010single,
author = {Kim, K I and Kwon, Y},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {6},
pages = {1127--1133},
publisher = {IEEE},
title = {{Single-image super-resolution using sparse regression and natural image prior}},
volume = {32},
year = {2010}
}
@inproceedings{newcombe2011kinectfusion,
author = {Newcombe, Richard A and Izadi, Shahram and Hilliges, Otmar and Molyneaux, David and Kim, David and Davison, Andrew J and Kohli, Pushmeet and Shotton, Jamie and Hodges, Steve and Fitzgibbon, Andrew W},
booktitle = {10th IEEE International Symposium on Mixed and Augmented Reality},
pages = {127--136},
title = {{KinectFusion: Real-time dense surface mapping and tracking}},
url = {http://dblp.org/db/conf/ismar/ismar2011.html#NewcombeIHMKDKSHF11},
year = {2011}
}
@inproceedings{strasdat2011double,
author = {Strasdat, H and Davison, A J and Montiel, J M M and Konolige, K},
booktitle = {Computer Vision (ICCV), 2011 IEEE International Conference on},
pages = {2352--2359},
title = {{Double window optimisation for constant time visual SLAM}},
year = {2011}
}
@inproceedings{michael2013real,
author = {Michael, Matthias and Salmen, Jan and Stallkamp, Johannes and Schlipsing, Marc},
booktitle = {IV Intelligent Vehicles Symposium},
organization = {IEEE},
pages = {1197--1202},
title = {{Real-time stereo vision: Optimizing semi-global matching}},
year = {2013}
}
@article{horn1990recovering,
author = {Horn, Berthold K P},
journal = {Journal of Optical Society of America},
title = {{Recovering baseline and orientation from essential matrix}},
year = {1990}
}
@article{tomasi1992shape,
author = {Tomasi, Carlo and Kanade, Takeo},
journal = {International Journal of Computer Vision},
number = {2},
pages = {137--154},
publisher = {Springer},
title = {{Shape and motion from image streams under orthography: a factorization method}},
volume = {9},
year = {1992}
}
@article{hosni2013fast,
author = {Hosni, Asmaa and Rhemann, Christoph and Bleyer, Michael and Rother, Carsten and Gelautz, Margrit},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {2},
pages = {504--511},
publisher = {IEEE},
title = {{Fast cost-volume filtering for visual correspondence and beyond}},
volume = {35},
year = {2013}
}
@inproceedings{wefelscheid2013openof,
author = {Wefelscheid, Cornelius and Hellwich, Olaf},
booktitle = {Proc. of the Intl. Conference on Computer Vision Theory and Applications (VISAPP), Volume 2, Barcelona, Spain, 21-24 February, 2013},
editor = {Battiato, Sebastiano and Braz, Jos\'{e}},
file = {:home/fradelg/Google Drive/TESIS/bib/wefelscheid2013openof.pdf:pdf},
isbn = {978-989-8565-48-8},
pages = {260--267},
publisher = {SciTePress},
title = {{OpenOF - Framework for Sparse Non-linear Least Squares Optimization on a GPU}},
year = {2013}
}
@article{whitaker1998level,
author = {Whitaker, R T},
journal = {International Journal of Computer Vision},
number = {3},
pages = {203--231},
publisher = {Kluwer Academic Publishers},
title = {{A level-set approach to 3D reconstruction from range data}},
volume = {29},
year = {1998}
}
@inproceedings{bodgan2011pcl,
address = {Shanghai, China},
author = {Rusu, Radu Bogdan and Cousins, Steve},
booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
month = may,
title = {{3D is here: Point Cloud Library (PCL)}},
url = {http://dblp.org/db/conf/icra/icra2011.html#RusuC11},
year = {2011}
}
@article{roy2004mesh,
author = {Roy, M and Foufou, S and Truchetet, F},
journal = {International Journal of Image and Graphics},
number = {01},
pages = {127--140},
publisher = {World Scientific},
title = {{Mesh comparison using attribute deviation metric}},
volume = {4},
year = {2004}
}
@inproceedings{aspert2002mesh,
author = {Aspert, N and Santa-Cruz, D and Ebrahimi, T},
booktitle = {Proceedings of the IEEE International Conference on Multimedia and Expo (ICME)},
pages = {705--708},
publisher = {IEEE},
title = {{Mesh: Measuring errors between surfaces using the hausdorff distance}},
volume = {1},
year = {2002}
}
@inproceedings{bleyer2011patchmatch,
author = {Bleyer, Michael and Rhemann, Christoph and Rother, Carsten},
booktitle = {BMVC},
pages = {1--11},
title = {{PatchMatch Stereo-Stereo Matching with Slanted Support Windows}},
volume = {11},
year = {2011}
}
@inproceedings{weise2009hand,
author = {Weise, T and Wismer, T and Leibe, B and {Van Gool}, L},
booktitle = {Computer Vision Workshops (ICCV Workshops), 2009 IEEE 12th International Conference on},
pages = {1630--1637},
title = {{In-hand scanning with online loop closure}},
year = {2009}
}
@inproceedings{kim2009realtime,
author = {Kim, Jun-Sik and Hwangbo, Myung and Kanade, Takeo},
booktitle = {IEEE 12th International Conference on Computer Vision Workshops},
organization = {IEEE},
pages = {886--893},
title = {{Realtime affine-photometric KLT feature tracker on GPU in CUDA framework}},
year = {2009}
}
@article{barnes2009patchmatch,
author = {Barnes, Connelly and Shechtman, Eli and Finkelstein, Adam and Goldman, Dan},
journal = {ACM Transactions on Graphics},
number = {3},
pages = {24},
title = {{PatchMatch: a randomized correspondence algorithm for structural image editing}},
volume = {28},
year = {2009}
}
@article{furukawa2010accurate,
author = {Furukawa, Y and Ponce, J},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {8},
pages = {1362--1376},
publisher = {IEEE},
title = {{Accurate, dense, and robust multiview stereopsis}},
volume = {32},
year = {2010}
}
@inproceedings{higo2010consensus,
author = {Higo, T and Matsushita, Y and Ikeuchi, K},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
pages = {1157--1164},
title = {{Consensus photometric stereo}},
year = {2010}
}
@inproceedings{curless1996volumetric,
author = {Curless, Brian and Levoy, Marc},
booktitle = {Proc. of the 23rd Annual Conference on Computer Graphics and Interactive Techniques},
organization = {ACM},
pages = {303--312},
title = {{A volumetric method for building complex models from range images}},
year = {1996}
}
@article{engel2013slam,
author = {Engel, Jakob and Sturm, Jurgen and Cremers, Daniel},
doi = {10.1109/ICCV.2013.183},
file = {:home/fradelg/Google Drive/TESIS/bib/engel2013iccv.pdf:pdf},
isbn = {978-1-4799-2840-8},
journal = {2013 IEEE International Conference on Computer Vision},
month = dec,
pages = {1449--1456},
publisher = {Ieee},
title = {{Semi-dense Visual Odometry for a Monocular Camera}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6751290},
year = {2013}
}
@book{reinhard2010high,
author = {Reinhard, E and Heidrich, W and Pattanaik, S and Debevec, P and Ward, G and Myszkowski, K},
publisher = {Morgan Kaufmann},
title = {{High dynamic range imaging: acquisition, display, and image-based lighting}},
year = {2010}
}
@misc{gallup2009cuda,
author = {Gallup, David and Frahm, Jan-michael and Stam, Joe},
booktitle = {North},
file = {:home/fradelg/Google Drive/TESIS/bib/gallup2009cuda.pdf:pdf},
pages = {1},
title = {{Real-Time Local Stereo Using CUDA}},
year = {2009}
}
@inproceedings{pradeep2013monofusion,
abstract = {MonoFusion allows a user to build dense 3D reconstructions of their environment in real-time, utilizing only a single, off-the-shelf web camera as the input sensor. The camera could be one already available in a tablet, phone, or a standalone device. No additional input hardware is required. This removes the need for power intensive active sensors that do not work robustly in natural outdoor lighting. Using the input stream of the camera we first estimate the 6DoF camera pose using a sparse tracking method. These poses are then used for efficient dense stereo matching between the input frame and a key frame (extracted previously). The resulting dense depth maps are directly fused into a voxel-based implicit model (using a computationally inexpensive method) and surfaces are extracted per frame. The system is able to recover from tracking failures as well as filter out geometrically inconsistent noise from the 3D reconstruction. Our method is both simple to implement and efficient, making such systems even more accessible. This paper details the algorithmic components that make up our system and a GPU implementation of our approach. Qualitative results demonstrate high quality reconstructions even visually comparable to active depth sensor-based systems such as KinectFusion.},
author = {Pradeep, Vivek and Rhemann, Christoph and Izadi, Shahram and Zach, Christopher and Bleyer, Michael and Bathiche, Steven},
booktitle = {Proc. of the IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
file = {:home/fradelg/Google Drive/TESIS/bib/pradeep2013monofusion.pdf:pdf},
pages = {83--88},
publisher = {IEEE},
title = {{MonoFusion: Real-time 3D reconstruction of small scenes with a single web camera}},
year = {2013}
}
@article{stewenius2006fivepoint,
abstract = {This paper presents a novel version of the five-point relative orientation algorithm given in Nister [Nister, D., 2004. An efficient solution to the five-point relative pose problem, IEEE Transactions on Pattern Analysis and Machine Intelligence, 26 (6), 756-770]. The name of the algorithm arises from the fact that it can operate even on the minimal five-point correspondences required for a finite number of solutions to relative orientation. For the minimal five correspondences, the algorithm returns up to 10 real solutions. The algorithm can also operate on many points. Like the previous version of the five-point algorithm, our method can operate correctly even in the face of critical surfaces, including planar and ruled quadric scenes. The paper presents comparisons with other direct methods, including the previously developed five-point method, two different six-point methods, the seven-point method, and the eight-point method. It is shown that the five-point method is superior in most cases among the direct methods. The new version of the algorithm was developed from the perspective of algebraic geometry and is presented in the context of computing a Gr??bner basis. The constraints are formulated in terms of polynomial equations in the entries of the fundamental matrix. The polynomial equations generate an algebraic ideal for which a Gr??bner basis is computed. The Gr??bner basis is used to compute the action matrix for multiplication by a single variable monomial. The eigenvectors of the action matrix give the solutions for all the variables and thereby also relative orientation. Using a Gr??bner basis makes the solution clear and easy to explain. ?? 2006 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS).},
author = {Stew\'{e}nius, Henrik and Engels, Christopher and Nist\'{e}r, David},
file = {:home/fradelg/Google Drive/TESIS/bib/stewenius2006fivepoint.pdf:pdf},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
keywords = {Five-point method,Grubner basis,Relative orientation,Six-point method},
number = {4},
pages = {284--294},
publisher = {Elsevier},
title = {{Recent developments on direct relative orientation}},
volume = {60},
year = {2006}
}
@article{zou2013coslam,
author = {Zou, Danping and Tan, Ping},
file = {:home/fradelg/Google Drive/TESIS/bib/zou2013coslam.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {2},
pages = {354--366},
publisher = {IEEE},
title = {{CoSLAM: Collaborative visual SLAM in dynamic environments}},
volume = {35},
year = {2013}
}
@inproceedings{lucas1981iterative,
author = {Lucas, Bruce D and Kanade, Takeo and Others},
booktitle = {Proc. of the Intl. Joint Conference on Artificial Intelligence},
pages = {674--679},
title = {{An iterative image registration technique with an application to stereo vision}},
volume = {81},
year = {1981}
}
@inproceedings{zach2008fast,
abstract = {Reconstructing the 3D surface from a set of provided range images acquired by active or passive sensors is an important step to generate faithful virtual models of real objects or environments. Since several approaches for high quality fusion of range images are already known, the run- time efficiency of the respective methods are of increased interest. In this paper we propose a highly efficient method for range image fusion resulting in very accurate 3D mod- els. We employ a variational formulation for the surface reconstruction task. The global optimal solution can be found by gradient descent due to the convexity of the under- lying energy functional. Further, the gradient descent pro- cedure can be parallelized, and consequently accelerated by graphics processing units. The quality and runtime per- formance of the proposed method is demonstrated on well- known multi-view stereo benchmark datasets.},
author = {Zach, Christopher},
booktitle = {Proc. of the Intl. Symposium on 3D Data Processing, Visualization and Transmission (3DPVT)},
file = {:home/fradelg/Google Drive/TESIS/bib/zach2008fusion.pdf:pdf},
pages = {1--8},
title = {{Fast and high quality fusion of depth maps}},
url = {http://www-static.cc.gatech.edu/conferences/3DPVT08/Program/Papers/paper196.pdf},
volume = {1},
year = {2008}
}
@book{baggio2012mastering,
author = {Baggio, Daniel L\'{e}lis},
file = {:home/fradelg/Google Drive/TESIS/bib/roy2012opencv.pdf:pdf},
publisher = {Packt Publishing Ltd},
title = {{Mastering OpenCV with Practical Computer Vision Projects}},
year = {2012}
}
@article{chan2005aspects,
author = {Chan, Tony F and Esedoglu, Selim},
journal = {SIAM Journal on Applied Mathematics},
number = {5},
pages = {1817--1837},
publisher = {SIAM},
title = {{Aspects of total variation regularized L 1 function approximation}},
volume = {65},
year = {2005}
}
@inproceedings{shi1994good,
author = {Shi, Jianbo and Tomasi, Carlo},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
pages = {593--600},
publisher = {IEEE},
title = {{Good features to track}},
year = {1994}
}
@article{varol2011monocular,
author = {Varol, A and Shaji, A and Salzmann, M and Fua, P},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
number = {99},
pages = {1},
publisher = {IEEE},
title = {{Monocular 3D Reconstruction of Locally Textured Surfaces}},
year = {2011}
}
@article{zhang2009depthmap,
author = {Zhang, Guofeng and Jia, Jiaya and Wong, Tien-Tsin and Bao, Hujun},
doi = {10.1109/TPAMI.2009.52},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
month = jun,
number = {6},
pages = {974--988},
title = {{Consistent Depth Maps Recovery from a Video Sequence}},
volume = {31},
year = {2009}
}
@inproceedings{xiao2009image,
author = {Xiao, J and Fang, T and Zhao, P and Lhuillier, M and Quan, L},
booktitle = {ACM Transactions on Graphics (TOG)},
number = {5},
pages = {114},
title = {{Image-based street-side city modeling}},
volume = {28},
year = {2009}
}
@incollection{bloomenthal1994polygonizer,
address = {San Diego, CA, USA},
author = {Bloomenthal, Jules},
chapter = {An Implici},
editor = {Heckbert, Paul S},
isbn = {0-12-336155-9},
pages = {324--349},
publisher = {Academic Press Professional, Inc.},
title = {{Graphics Gems IV}},
url = {http://dl.acm.org/citation.cfm?id=180895.180923},
year = {1994}
}
@article{rudin1992nonlinear,
author = {Rudin, Leonid I and Osher, Stanley and Fatemi, Emad},
journal = {Physica D: Nonlinear Phenomena},
number = {1},
pages = {259--268},
publisher = {Elsevier},
title = {{Nonlinear total variation based noise removal algorithms}},
volume = {60},
year = {1992}
}
@inproceedings{klein2007parallel,
abstract = {This paper presents a method of estimating camera pose in an unknown scene. While this has previously been attempted by adapting SLAM algorithms developed for robotic exploration, we propose a system specifically designed to track a hand-held camera in a small AR workspace. We propose to split tracking and mapping into two separate tasks, processed in parallel threads on a dual-core computer: one thread deals with the task of robustly tracking erratic hand-held motion, while the other produces a 3D map of point features from previously observed video frames. This allows the use of computationally expensive batch optimisation techniques not usually associated with real-time operation: The result is a system that produces detailed maps with thousands of landmarks which can be tracked at frame-rate, with an accuracy and robustness rivalling that of state-of-the-art model-based systems.},
author = {Klein, Georg and Murray, David},
booktitle = {Proceedings of the 6th International Symposium on Mixed and Augmented Reality (ISMAR)},
file = {:home/fradelg/Google Drive/TESIS/bib/klein2007ptam.pdf:pdf},
pages = {225--234},
title = {{Parallel tracking and mapping for small AR workspaces}},
year = {2007}
}
@article{devernay2001straight,
author = {Devernay, Frederic and Faugeras, Olivier},
journal = {Machine vision and applications},
number = {1},
pages = {14--24},
publisher = {Springer},
title = {{Straight lines have to be straight}},
volume = {13},
year = {2001}
}
@book{hartley2003multiple,
author = {Hartley, Richard and Zisserman, Andrew},
publisher = {Cambridge University Press},
title = {{Multiple view geometry in computer vision}},
year = {2003}
}
@article{liu2010point,
author = {Liu, Y and Dai, Q and Xu, W},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {3},
pages = {407--418},
publisher = {IEEE},
title = {{A point-cloud-based multiview stereo algorithm for free-viewpoint video}},
volume = {16},
year = {2010}
}
@inproceedings{elseberg2011efficient,
author = {Elseberg, J and Borrmann, D and Nuchter, A},
booktitle = {Proceedings of the XXIII International Symposium on Information, Communication and Automation Technologies (ICAT)},
pages = {1--7},
title = {{Efficient processing of large 3D point clouds}},
year = {2011}
}
@inproceedings{verhagen2014lines,
abstract = {In this paper we propose a method to add scale-invariance to line descriptors for wide baseline matching purposes. While finding point correspondences among different views is a well-studied problem, there still remain difficult cases where it performs poorly, such as textureless scenes, ambiguities and extreme transformations. For these cases using line segment correspondences is a valuable addition for finding sufficient matches. Our general method for adding scale-invariance to line segment descriptors consist of 5 basic rules. We apply these rules to enhance both the line descriptor described by Bay et al. [1] and the mean-standard deviation line descriptor (MSLD) proposed by Wang et al. [14]. Moreover, we examine the effect of the line descriptors when combined with the topological filtering method proposed by Bay et al. and the recent proposed graph matching strategy from K-VLD [6]. We validate the method using standard point correspondence benchmarks and more challenging new ones. Adding scale-invariance increases the accuracy when confronted with big scale changes and increases the number of inliers in the general case, both resulting in smaller calibration errors by means of RANSAC-like techniques and epipolar estimations.},
author = {Verhagen, Bart and Timofte, Radu and {Van Gool}, Luc},
booktitle = {IEEE Winter Conference on Applications of Computer Vision},
doi = {10.1109/WACV.2014.6836061},
file = {:home/fradelg/Google Drive/TESIS/bib/verhagen2014smsld.pdf:pdf},
keywords = {Accuracy,Data mining,Detectors,Image color analysis,Image segmentation,Lighting,Robustness,image features},
mendeley-tags = {image features},
pages = {493--500},
shorttitle = {Applications of Computer Vision (WACV), 2014 IEEE},
title = {{Scale-invariant line descriptors for wide baseline matching}},
year = {2014}
}
@article{drummond2002real,
author = {Drummond, Tom and Cipolla, Roberto},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
number = {7},
pages = {932--946},
publisher = {IEEE},
title = {{Real-time visual tracking of complex structures}},
volume = {24},
year = {2002}
}
@inproceedings{clemente2007mapping,
author = {Clemente, L A and Davison, A J and Reid, I and Neira, J and Tardos, J D},
booktitle = {Robotics: Science and Systems},
title = {{Mapping large loops with a single hand-held camera}},
year = {2007}
}
@inproceedings{newcombe2010dtam,
abstract = {We present a method which enables rapid and dense reconstruction of scenes browsed by a single live camera. We take point-based real-time structure from motion (SFM) as our starting point, generating accurate 3D camera pose estimates and a sparse point cloud. Our main novel contribution is to use an approximate but smooth base mesh generated from the SFM to predict the view at a bundle of poses around automatically selected reference frames spanning the scene, and then warp the base mesh into highly accurate depth maps based on view-predictive optical flow and a constrained scene flow update. The quality of the resulting depth maps means that a convincing global scene model can be obtained simply by placing them side by side and removing overlapping regions. We show that a cluttered indoor environment can be reconstructed from a live hand-held camera in a few seconds, with all processing performed by current desktop hardware. Real-time monocular dense reconstruction opens up many application areas, and we demonstrate both real-time novel view synthesis and advanced augmented reality where augmentations interact physically with the 3D scene and are correctly clipped by occlusions.},
author = {Newcombe, Richard a. and Davison, Andrew J.},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
file = {:home/fradelg/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Newcombe, Davison - 2010 - Live dense reconstruction with a single moving camera.pdf:pdf},
isbn = {9781424469857},
pages = {1498--1505},
title = {{Live dense reconstruction with a single moving camera}},
year = {2010}
}
@article{aanes2011sinteresting,
author = {Aan\ae s, H and Dahl, A L and {Steenstrup Pedersen}, K},
journal = {International Journal of Computer Vision},
pages = {18--35},
publisher = {Springer},
title = {{Interesting Interest Points}},
volume = {97},
year = {2012}
}
@article{yang2013bilateral,
abstract = {This paper presents a new bilateral filtering method specially designed for practical stereo vision systems. Parallel algorithms are preferred in these systems due to the real-time performance requirement. Edge-preserving filters like the bilateral filter have been demonstrated to be very effective for high-quality local stereo matching. A hardware-efficient bilateral filter is thus proposed in this paper. When moved to an NVIDIA GeForce GTX 580 GPU, it can process a one megapixel textit{color} image at around 417 frames per second. This filter can be directly used for cost aggregation required in any local stereo matching algorithm. Quantitative evaluation shows that it outperforms all the other local stereo methods both in terms of accuracy and speed on Middlebury benchmark. It ranks $12^{th}$ out of over 120 methods on Middlebury data sets, and the average runtime (including the matching cost computation, occlusion handling and post processing) is only 15 milliseconds (67 frames per second).},
author = {Yang, Qingxiong},
doi = {10.1109/TPAMI.2013.186},
file = {:home/fradelg/Google Drive/TESIS/bib/yang2013bilateral.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {5},
pages = {1--1},
title = {{Hardware-Efficient Bilateral Filtering for Stereo Matching}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6616530},
volume = {36},
year = {2013}
}
@inproceedings{meistercan2012kinect,
author = {Meister, S and Izadi, S and Kohli, P and H\"{a}mmerle, M and Rother, C and Kondermann, D},
booktitle = {Proceedings of the IEEE/RSJ International Conference in Intelligent Robots and Systems (IROS)},
publisher = {IEEE},
title = {{When Can We Use KinectFusion for Ground Truth Acquisition?}},
year = {2012}
}
@inproceedings{salas2013slampp,
author = {Salas-Moreno, Renato F and Newcombe, Richard A and Strasdat, Hauke and Kelly, Paul H J and Davison, Andrew J},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = jun,
title = {{SLAM++: Simultaneous Localisation and Mapping at the Level of Objects}},
year = {2013}
}
@article{ma2001optimization,
abstract = {Prevailing efforts to study the standard formulation of motion and structure recovery have recently been focused on issues of sensitivity and robustness of existing techniques. While many cogent observations have been made and verified experimentally, many statements do not hold in general settings and make a comparison of existing techniques difficult. With an ultimate goal of clarifying these issues, we study the main aspects of motion and structure recovery: the choice of objective function, optimization techniques and sensitivity and robustness issues in the presence of noise. We clearly reveal the relationship among different objective functions, such as “(normalized) epipolar constraints,” “reprojection error” or “triangulation,” all of which can be unified in a new “optimal triangulation” procedure. Regardless of various choices of the objective function, the optimization problems all inherit the same unknown parameter space, the so-called “essential manifold.” Based on recent developments of optimization techniques on Riemannian manifolds, in particular on Stiefel or Grassmann manifolds, we propose a Riemannian Newton algorithm to solve the motion and structure recovery problem, making use of the natural differential geometric structure of the essential manifold. We provide a clear account of sensitivity and robustness of the proposed linear and nonlinear optimization techniques and study the analytical and practical equivalence of different objective functions. The geometric},
author = {Ma, Yi and Kosecka, Jana and Sastry, Shankar and Ko\v{s}eck\'{a}, Jana},
file = {:home/fradelg/Google Drive/TESIS/bib/ma2001optimization.pdf:pdf},
journal = {International Journal of Computer Vision},
keywords = {Essential manifold,Motion and structure recovery,Optimal triangulation,Riemannian Newton's algorithm,Stiefel manifold},
number = {3},
pages = {219--249},
publisher = {Springer},
title = {{Optimization criteria and geometric algorithms for motion and structure estimation}},
volume = {44},
year = {2001}
}
@phdthesis{gallup2011phd,
author = {Gallup, David},
file = {:home/fradelg/Google Drive/TESIS/bib/gallup2011phd.pdf:pdf},
pages = {137},
title = {{Efficient 3d reconstruction of large-scale urban environments from street-level video}},
year = {2011}
}
@article{nister2004efficient,
author = {Nist\'{e}r, David},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {6},
pages = {756--770},
publisher = {IEEE},
title = {{An efficient solution to the five-point relative pose problem}},
volume = {26},
year = {2004}
}
@inproceedings{liu2009continuous,
author = {Liu, Y and Cao, X and Dai, Q and Xu, W},
booktitle = {Proceeding of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
pages = {2121--2128},
title = {{Continuous depth estimation for multi-view stereo}},
year = {2009}
}
@article{lourakis2009sba,
author = {Lourakis, Manolis I A and Argyros, Antonis A},
journal = {ACM Transactions on Mathematical Software (TOMS)},
number = {1},
pages = {2},
publisher = {ACM},
title = {{SBA: A software package for generic sparse bundle adjustment}},
volume = {36},
year = {2009}
}
@inproceedings{vedula1999sceneflow,
abstract = {Scene flow is the three-dimensional motion field of points in the world, just as optical flow is the two- dimensionalmotion field of points in an image. Any optical flow is simply the projection of the scene flow onto the im- age plane of a camera. In this paper, we present a frame- work for the computation of dense, non-rigid scene flow from optical flow. Our approach leads to straightforward linear algorithms and a classification of the task into three major scenarios: (1) complete instantaneous knowledge of the scene structure, (2) knowledge only of correspondence information, and (3) no knowledge of the scene structure. We also show that multiple estimates of the normal flow cannot be used to estimate dense scene flow directly with- out some form of smoothing or regularization.},
author = {Vedula, S. and Baker, S. and Rander, P. and Collins, R. and Kanade, T.},
booktitle = {Proceedings of the 7th IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.1999.790293},
file = {:home/fradelg/Google Drive/TESIS/bib/vedula1999sceneflow.pdf:pdf},
isbn = {0-7695-0164-8},
pages = {722--729},
publisher = {IEEE},
shorttitle = {Computer Vision, 1999. The Proceedings of the Seve},
title = {{Three-dimensional scene flow}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=790293},
volume = {2},
year = {1999}
}
@inproceedings{newcombe2011dtam,
author = {Newcombe, R A and Lovegrove, S and Davison, A J},
booktitle = {International Conference on Computer Vision (ICCV), Barcelona, Spain},
title = {{DTAM: Dense tracking and mapping in real-time}},
volume = {1},
year = {2011}
}
@misc{agarwal2010ceres,
author = {Agarwal, Sameer and Mierle, Keir and Others},
howpublished = {\url{https://code.google.com/p/ceres-solver}},
title = {{Ceres Solver}}
}
@book{blake2011mrf,
author = {Blake, Andrew and Kohli, Pushmeet and Rother, Carsten},
file = {:home/fradelg/Google Drive/TESIS/bib/blake2011markov.pdf:pdf},
publisher = {MIT Press},
title = {{Markov random fields for vision and image processing}},
year = {2011}
}
@inproceedings{tung2009complete,
author = {Tung, T and Nobuhara, S and Matsuyama, T},
booktitle = {Computer Vision, 2009 IEEE 12th International Conference on},
pages = {1709--1716},
title = {{Complete multi-view reconstruction of dynamic scenes from probabilistic fusion of narrow and wide baseline stereo}},
year = {2009}
}
